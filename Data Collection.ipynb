{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# coding:utf-8\n",
    "# Textual analysis through the open web\n",
    "from __future__ import print_function\n",
    "import io\n",
    "import os\n",
    "import re\n",
    "import bs4\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import nltk\n",
    "import urllib\n",
    "import pprint\n",
    "import random\n",
    "import string\n",
    "import requests\n",
    "import wikipedia\n",
    "import itertools\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def scrape_wiki(title):\n",
    "    try:\n",
    "        searchstring = title\n",
    "        summary = wikipedia.summary(searchstring)\n",
    "        print(__success(searchstring))\n",
    "    except wikipedia.DisambiguationError:\n",
    "        try:\n",
    "            searchstring = u'{} (video game)'.format(title).replace(u' ', u'_')\n",
    "            summary = wikipedia.page(searchstring, auto_suggest=False).summary\n",
    "            print(__success(searchstring))\n",
    "        except wikipedia.DisambiguationError:\n",
    "            searchstring = u'{} (Unix video game)'.format(title).replace(u' ', u'_')\n",
    "            summary = wikipedia.page(searchstring, auto_suggest=False).summary\n",
    "            print(__success(searchstring))\n",
    "        except wikipedia.PageError:\n",
    "            summary = 'No summary found on Wikipedia.'\n",
    "            print(__warning(u'Wikipedia cannot find \"{}\"'.format(searchstring)))\n",
    "    except wikipedia.PageError:\n",
    "        try:\n",
    "            summary = wikipedia.page(searchstring, auto_suggest=False).summary\n",
    "            print(__success(searchstring))\n",
    "        except wikipedia.PageError:\n",
    "            summary = 'No summary found on Wikipedia.'\n",
    "            print(__warning(u'Search term \"{}\" returned nothing'.format(searchstring)))\n",
    "    return summary\n",
    "\n",
    "def scrape_duckduckgo(keywords, developer=\"\"):\n",
    "    searchstring = u'\"{}\" {} {}'.format(keywords, developer, u'interview game')\n",
    "    response = requests.get(u'http://duckduckgo.com/html/?q={}'.format(\n",
    "                urllib.quote(searchstring.encode('utf-8'))),\n",
    "                            timeout=(9.1, 12.1)\n",
    "             )\n",
    "    print(__message(u'DDG: {}'.format(searchstring)))\n",
    "    soup = bs4.BeautifulSoup(response.text)\n",
    "    links = []\n",
    "    for node in soup.select('div.web-result'):\n",
    "        if 'web-result-sponsored' in node['class']:\n",
    "            continue\n",
    "        try:\n",
    "            links.append(node.select('a.large')[0].get('href'))\n",
    "        except Exception as e:\n",
    "            print(__failure(e))\n",
    "            pass\n",
    "    if links:\n",
    "        print(__success(u'DDG: {}'.format(searchstring)))\n",
    "        print('\\t\\t\\n'.join(links))\n",
    "    return links\n",
    "\n",
    "def scrape(url):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=(10, 15))\n",
    "    except Exception as e:\n",
    "        print(__failure(u'Failed to load {}'.format(url)))\n",
    "        print(e)\n",
    "        return None\n",
    "    \n",
    "    return response.text\n",
    "    \n",
    "def read_json(path):\n",
    "    data = ''\n",
    "    with io.open(path, 'r', encoding='utf-8') as f:\n",
    "        data = json.loads(f.read())\n",
    "        print(__message(u'Loaded {}'.format(path)))\n",
    "    return data\n",
    "    \n",
    "def save_json(path, data):\n",
    "    with io.open(path, 'w', encoding='utf-8') as f:\n",
    "        try:\n",
    "            output = json.dumps(data, indent=2, ensure_ascii=False)\n",
    "            f.write(output)\n",
    "        except UnicodeEncodeError:\n",
    "            f.write(output.encode('utf-8'))\n",
    "    print(__message(u'Written to {}'.format(path)))\n",
    "        \n",
    "def __success(text):\n",
    "    return u'  (SUCC) {}'.format(text).encode('utf-8')\n",
    "    \n",
    "def __failure(text):\n",
    "    return u'!!FAIL!! {}'.format(text).encode('utf-8')\n",
    "    \n",
    "def __warning(text):\n",
    "    return u'??WARN?? {}'.format(text).encode('utf-8')\n",
    "    \n",
    "def __message(text):\n",
    "    return u'   |MSG| {}'.format(text).encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Scrape for links\n",
    "game_meta = read_json(os.path.join(os.getcwd(), 'data', 'game-sources.json'))\n",
    "\n",
    "shuffled_game_meta = game_meta.items()\n",
    "random.shuffle(shuffled_game_meta)\n",
    "for game, meta in shuffled_game_meta:\n",
    "    game_meta[game]['Links'] += scrape_duckduckgo(game, game_meta[game]['Developer'])\n",
    "    game_meta[game]['Links'] = list(set(game_meta[game]['Links']))\n",
    "    save_json(os.path.join(os.getcwd(), 'data', 'game-sources.json'), game_meta)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load content in search results\n",
    "game_meta = read_json(os.path.join(os.getcwd(), 'data', 'game-sources.json'))\n",
    "cached = read_json(os.path.join(os.getcwd(), 'data', 'corpus.json'))\n",
    "\n",
    "output = cached\n",
    "for game, meta in game_meta.items():\n",
    "    if game not in output:\n",
    "        output[game] = {}\n",
    "    print(__message(game))\n",
    "    for url in meta['Links']:\n",
    "        if url in output[game] and output[game][url]:\n",
    "            continue\n",
    "        data = []\n",
    "        html = scrape(url)\n",
    "        if any(word in html.lower() for word in ['interview', 'mortem', 'review', 'history']):\n",
    "            soup = bs4.BeautifulSoup(html)\n",
    "            content = soup.select('div > p') + soup.select('body > p')\n",
    "            data = [c.string.strip() for c in content if c.string and c.string.strip()]\n",
    "            output[game][url] = data\n",
    "            print(__message(u'Scrapped {}'.format(url)))\n",
    "            save_json(os.path.join(os.getcwd(), 'data', 'corpus.json'), output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Locate mentions of games\n",
    "game_LUT = set(read_json(os.path.join(os.getcwd(), 'data', 'games.json')))\n",
    "game_meta = read_json(os.path.join(os.getcwd(), 'data', 'game-sources.json'))\n",
    "game_articles = read_json(os.path.join(os.getcwd(), 'data', 'corpus.json'))\n",
    "not_games = set(read_json(os.path.join(os.getcwd(), 'data', 'not-games.json')))\n",
    "\n",
    "# Create a look up table for games\n",
    "roguelike_LUT = {}\n",
    "for game, meta in game_meta.items():\n",
    "    roguelike_LUT[game] = game\n",
    "    if 'AKA' in meta:\n",
    "        for aka in meta['AKA']:\n",
    "            roguelike_LUT[aka] = game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Look through the interview articles\n",
    "roguelike_relations = {}\n",
    "other_relations = {}\n",
    "for game, articles in game_articles.items():\n",
    "    roguelike_relations[game] = []\n",
    "    other_relations[game] = []\n",
    "    counter = collections.Counter()\n",
    "    for url, article in articles.items():\n",
    "        # Intersection for fast search\n",
    "        things = []\n",
    "        current = u''\n",
    "        for paragraph in article:\n",
    "            for token in paragraph.split():\n",
    "                if re.compile(\"^[A-Z0-9][\\w:']*[\\w:']|[A-Z\\.]+$\").match(token) or \\\n",
    "                        (current and token in ('the', 'of', 'no', 'to')):\n",
    "                    current += u'{} '.format(token)\n",
    "                elif current:\n",
    "                    things.append(current.strip())\n",
    "                    current = u''\n",
    "        roguelike_things = [roguelike_LUT[s] for s in things if s in roguelike_LUT]\n",
    "        if roguelike_things:\n",
    "            roguelike_relations[game].extend(roguelike_things)\n",
    "        other_things = [s for s in things if\n",
    "                            s in game_LUT and\n",
    "                            s not in not_games and\n",
    "                            s not in roguelike_LUT and\n",
    "                            len(s) > 1 and\n",
    "                            not s.isdigit()]\n",
    "        if other_things:\n",
    "            other_relations[game].extend(other_things)\n",
    "\n",
    "# print(\"\\n### ROGUELIKES ###\\n\")\n",
    "# pprint.pprint(roguelike_relations, indent=2)\n",
    "# print(\"\\n### OTHER GAMES ###\\n\")\n",
    "# pprint.pprint(other_relations, indent=2)\n",
    "\n",
    "save_json(os.path.join(os.getcwd(), 'generated', 'roguelike-relations.json'), roguelike_relations)\n",
    "save_json(os.path.join(os.getcwd(), 'generated', 'other-relations.json'), other_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Construct influence network\n",
    "\n",
    "roguelike_relations = read_json(os.path.join(os.getcwd(), 'generated', 'roguelike-relations.json'))\n",
    "other_relations = read_json(os.path.join(os.getcwd(), 'generated', 'other-relations.json'))\n",
    "games_years = read_json(os.path.join(os.getcwd(), 'generated', 'games-years.json'))\n",
    "\n",
    "roguelike_influence = {}\n",
    "for roguelike, other_roguelikes in roguelike_relations.items():\n",
    "    roguelike_influence[roguelike] = []\n",
    "    \n",
    "    roguelike_relation_counter = collections.Counter()\n",
    "    for other_roguelike in other_roguelikes:\n",
    "        if other_roguelike != roguelike:\n",
    "            roguelike_relation_counter[other_roguelike] += 1\n",
    "            \n",
    "    other_relation_counter = collections.Counter()\n",
    "    for other_relation in other_relations[roguelike]:\n",
    "        if other_relation != roguelike:\n",
    "            other_relation_counter[other_relation] += 1\n",
    "            \n",
    "    for roguelike_relation in roguelike_relation_counter.most_common(5):\n",
    "        roguelike_influence[roguelike].append(roguelike_relation[0])\n",
    "        \n",
    "    for other_relation in other_relation_counter.most_common(5):\n",
    "        if other_relation[1] > 1:\n",
    "            roguelike_influence[roguelike].append(other_relation[0])\n",
    "            \n",
    "#     print(u'{}\\n{}\\n{}\\n'.format(roguelike, \n",
    "#                                    roguelike_relation_counter.most_common(3), \n",
    "#                                    other_relation_counter.most_common(3)))\n",
    "\n",
    "games_set_small = set(itertools.chain(*(roguelike_relations.values()+other_relations.values())))\n",
    "    \n",
    "games_years_small = {game: int(year) for game, year in games_years.items() if game in games_set_small}\n",
    "    \n",
    "print(games_years_small)\n",
    "                                                        \n",
    "save_json(os.path.join(os.getcwd(), 'generated', 'relations.json'), roguelike_influence)\n",
    "save_json(os.path.join(os.getcwd(), 'generated', 'games-years-small.json'), games_years_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
