{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# coding:utf-8\n",
    "# Textual analysis through the open web\n",
    "from __future__ import print_function\n",
    "import io\n",
    "import os\n",
    "import bs4\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import urllib\n",
    "import requests\n",
    "import wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_json(path):\n",
    "    data = ''\n",
    "    with io.open(path, 'r', encoding='utf-8') as f:\n",
    "        data = json.loads(f.read())\n",
    "        print(__message('Loaded {}'.format(path)))\n",
    "    return data\n",
    "    \n",
    "def modify_game_meta(data):\n",
    "    for k, v in data.items():\n",
    "        data[k].pop('Last', None)\n",
    "        data[k]['Year'] = int(data[k]['First'][:4])\n",
    "        data[k].pop('First', None)\n",
    "        data[k].pop('Title', None)\n",
    "        data[k]['Summary'] = scrape_wiki(k)\n",
    "        \n",
    "#         # Scraping Duck Duck Go\n",
    "#         print(__message('Scraping DuckDuckGo for a list of URLs...'))\n",
    "#         new_links = scrape_duckduckgo(k, data[k]['Developer'])\n",
    "#         data[k]['Links'] = new_links | set(data[k]['Links'])\n",
    "\n",
    "    print(__message('Done'))\n",
    "    return data\n",
    "\n",
    "def scrape_wiki(title):\n",
    "    try:\n",
    "        searchstring = title\n",
    "        summary = wikipedia.summary(searchstring)\n",
    "        print(__success(searchstring))\n",
    "    except wikipedia.DisambiguationError:\n",
    "        try:\n",
    "            searchstring = u'{} (video game)'.format(title).replace(u' ', u'_')\n",
    "            summary = wikipedia.page(searchstring, auto_suggest=False).summary\n",
    "            print(__success(searchstring))\n",
    "        except wikipedia.DisambiguationError:\n",
    "            searchstring = u'{} (Unix video game)'.format(title).replace(u' ', u'_')\n",
    "            summary = wikipedia.page(searchstring, auto_suggest=False).summary\n",
    "            print(__success(searchstring))\n",
    "        except wikipedia.PageError:\n",
    "            summary = 'No summary found on Wikipedia.'\n",
    "            print(__warning('Wikipedia cannot find \"{}\"'.format(searchstring)))\n",
    "    except wikipedia.PageError:\n",
    "        try:\n",
    "            summary = wikipedia.page(searchstring, auto_suggest=False).summary\n",
    "            print(__success(searchstring))\n",
    "        except wikipedia.PageError:\n",
    "            summary = 'No summary found on Wikipedia.'\n",
    "            print(__warning('Search term \"{}\" returned nothing'.format(searchstring)))\n",
    "    return summary\n",
    "\n",
    "def scrape_duckduckgo(keywords, developer=\"\"):\n",
    "    searchstring = u'\"{}\" {} {}'.format(keywords, developer, u'interview game')\n",
    "    response = requests.get('http://duckduckgo.com/html/?q={}'.format(\n",
    "                urllib.quote(searchstring)),\n",
    "                timeout=(10, 15)\n",
    "             )\n",
    "    print(__message(u'DDG: {}'.format(searchstring)))\n",
    "    soup = bs4.BeautifulSoup(response.text)\n",
    "    links = []\n",
    "    for node in soup.select('div.web-result'):\n",
    "        if 'web-result-sponsored' in node['class']:\n",
    "            continue\n",
    "        try:\n",
    "            links.append(node.select('a.large')[0].get('href'))\n",
    "        except Exception as e:\n",
    "            print(__failure(e))\n",
    "            pass\n",
    "    if links:\n",
    "        print(__success(u'DDG: {}'.format(searchstring)))\n",
    "    return links\n",
    "\n",
    "def scrape_url(url):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=(10, 15))\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(__failure(e))\n",
    "\n",
    "def clean_url_data(links, data):\n",
    "    links = set(links)\n",
    "    for link in data.keys():\n",
    "        if link not in links:\n",
    "            data.pop(link, None)\n",
    "    return data\n",
    "    \n",
    "def save_json(path, data):\n",
    "    with io.open(path, 'w', encoding='utf-8') as f:\n",
    "        try:\n",
    "            output = json.dumps(data, indent=2, ensure_ascii=False)\n",
    "            f.write(output)\n",
    "        except UnicodeEncodeError:\n",
    "            f.write(output.encode('utf-8'))\n",
    "    print(__message(u'Written to {}'.format(path)))\n",
    "        \n",
    "def __success(text):\n",
    "    return u'  (SUCC) {}'.format(text).encode('utf-8')\n",
    "    \n",
    "def __failure(text):\n",
    "    return u'!!FAIL!! {}'.format(text).encode('utf-8')\n",
    "    \n",
    "def __warning(text):\n",
    "    return u'??WARN?? {}'.format(text).encode('utf-8')\n",
    "    \n",
    "def __message(text):\n",
    "    return u'   |MSG| {}'.format(text).encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   |MSG| Loaded /Users/spaxe/dev/roguelike-universe/data/game-sources.json\n",
      "   |MSG| Loaded /Users/spaxe/dev/roguelike-universe/data/game-articles.json\n",
      "  (SUCC) Dungeon\n",
      "  (SUCC) Falcon's Eye\n",
      "  (SUCC) Island of Kesmai\n",
      "  (SUCC) Torneko no Daiboken: Fushigi no Dungeon\n",
      "  (SUCC) Pokémon Mystery Dungeon: Explorers of Sky\n",
      "  (SUCC) Linley's Dungeon Crawl\n",
      "  (SUCC) Tales of Middle Earth\n",
      "  (SUCC) TowerClimb\n",
      "  (SUCC) Teleglitch\n",
      "  (SUCC) Brogue\n",
      "??WARN?? Search term \"Deadly Dungeons\" returned nothing\n",
      "  (SUCC) Advanced Dungeons & Dragons: Cloudy Mountain\n",
      "  (SUCC) Dungeon Hack\n",
      "  (SUCC) Dungeon of Doom\n",
      "  (SUCC) Dungeon Crawl Stone Soup\n",
      "  (SUCC) Slash'EM\n",
      "  (SUCC) Beneath Apple Manor\n",
      "  (SUCC) Mystery Dungeon: Shiren the Wanderer\n",
      "  (SUCC) Smart Kobold\n",
      "  (SUCC) Larn_(video_game)\n",
      "  (SUCC) Lost Labyrinth\n",
      "  (SUCC) Tower of Guns\n",
      "  (SUCC) Omega (video game)\n",
      "  (SUCC) UnReal World\n",
      "  (SUCC) Dragon Quest: Shonen Yangus to Fushigi no Dungeon\n",
      "  (SUCC) Wizards Encounters\n",
      "  (SUCC) Rogue Legacy\n",
      "  (SUCC) The Binding of Isaac\n",
      "  (SUCC) Dark Chronicle\n",
      "  (SUCC) Doom, the Roguelike\n",
      "  (SUCC) Risk of Rain\n",
      "  (SUCC) Rogue_(video_game)\n",
      "  (SUCC) Adventure\n",
      "  (SUCC) Sword of Fargoal\n",
      "  (SUCC) Pokémon Mystery Dungeon: Explorers of Darkness\n",
      "  (SUCC) Sword of the Stars: The Pit\n",
      "  (SUCC) Castle of the Winds\n",
      "  (SUCC) Nightmare of Druaga: Fushigino Dungeon\n",
      "  (SUCC) FTL: Faster Than Light\n",
      "  (SUCC) The Guided Fate Paradox\n",
      "  (SUCC) Shiren the Wanderer\n",
      "  (SUCC) Mission Thunderbolt\n",
      "  (SUCC) Moraff's World\n",
      "  (SUCC) Moria_(video_game)\n",
      "  (SUCC) Scarab of Ra\n",
      "  (SUCC) Z.H.P. Unlosing Ranger VS Darkdeath Evilman\n",
      "  (SUCC) Izuna 2: The Unemployed Ninja Returns\n",
      "  (SUCC) Hack_(Unix_video_game)\n",
      "  (SUCC) Chocobo's Dungeon 2\n",
      "  (SUCC) Azure Dreams\n",
      "  (SUCC) Fushigi no Dungeon: Fūrai no Shiren 2: Oni Shūrai! Siren-jō!\n",
      "  (SUCC) Don't Starve\n",
      "  (SUCC) 100 Rogues\n",
      "  (SUCC) Ancient Domains of Mystery\n",
      "  (SUCC) Infinite Space III: Sea of Stars\n",
      "  (SUCC) Dark Cloud\n",
      "  (SUCC) Izuna: Legend of the Unemployed Ninja\n",
      "  (SUCC) Baroque\n",
      "  (SUCC) Weird Worlds: Return to Infinite Space\n",
      "  (SUCC) World of Arch\n",
      "  (SUCC) Chocobo no Fushigina Dungeon\n",
      "  (SUCC) The Sorcerer's Cave\n",
      "  (SUCC) Moraff's Revenge\n",
      "  (SUCC) Torneko: The Last Hope\n",
      "  (SUCC) NetHack\n",
      "  (SUCC) Strange Adventures In Infinite Space\n",
      "  (SUCC) Dragon Crystal\n",
      "  (SUCC) Dungeons of the Unforgiven\n",
      "  (SUCC) Pokémon Mystery Dungeon: Explorers of Time\n",
      "  (SUCC) Tales of Maj'Eyal\n",
      "  (SUCC) Spelunky\n",
      "  (SUCC) Slaves to Armok II: Dwarf Fortress\n",
      "  (SUCC) Dungeons of Dredmor\n",
      "  (SUCC) Final Fantasy Fables: Chocobo's Dungeon\n",
      "  (SUCC) Telengard\n",
      "??WARN?? Wikipedia cannot find \"WazHack_(video_game)\"\n",
      "  (SUCC) Angband\n",
      "  (SUCC) Tao's Adventure: Curse of the Demon Seal\n",
      "??WARN?? Search term \"Alphaman\" returned nothing\n",
      "  (SUCC) 99 Levels to Hell\n",
      "  (SUCC) Not the Robots\n",
      "  (SUCC) Fatal Labyrinth\n",
      "  (SUCC) Pokémon Mystery Dungeon\n",
      "   |MSG| Done\n",
      "   |MSG| Written to /Users/spaxe/dev/roguelike-universe/generated/processed-game-articles.json\n",
      "   |MSG| Written to /Users/spaxe/dev/roguelike-universe/generated/processed-game-sources.json\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "\n",
    "game_meta = read_json(os.path.join(cwd, 'data', 'game-sources.json'))\n",
    "game_articles = read_json(os.path.join(cwd, 'data', 'game-articles.json'))\n",
    "\n",
    "# Format and standardise metadata\n",
    "game_meta = modify_game_meta(game_meta)\n",
    "\n",
    "# Clean up unused data in processing\n",
    "for article, data in game_articles.items():\n",
    "    if article not in game_meta:\n",
    "        game_articles.pop(article, None)\n",
    "        continue\n",
    "    game_articles[article] = clean_url_data(game_meta[article]['Links'], data)\n",
    "\n",
    "# # Scrape new data from URL\n",
    "# for k, v in game_meta.items():\n",
    "#     for link in game_meta[k]['Links']:\n",
    "#         if k not in game_articles:\n",
    "#             game_articles[k] = {}\n",
    "#         if link not in game_articles[k] or not game_articles[k][link]:\n",
    "#             game_articles[k][link] = scrape_url(link)\n",
    "#             print(__message('Scraped {} in {}'.format(k, link)))\n",
    "            \n",
    "save_json(os.path.join(cwd, 'generated', 'processed-game-articles.json'), game_articles)\n",
    "save_json(os.path.join(cwd, 'generated', 'processed-game-sources.json'), game_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
